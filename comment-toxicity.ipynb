{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-22T05:28:20.540745Z","iopub.execute_input":"2023-02-22T05:28:20.541184Z","iopub.status.idle":"2023-02-22T05:28:20.608619Z","shell.execute_reply.started":"2023-02-22T05:28:20.541100Z","shell.execute_reply":"2023-02-22T05:28:20.607628Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\n/kaggle/input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip\n/kaggle/input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip\n/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:28:20.610553Z","iopub.execute_input":"2023-02-22T05:28:20.612212Z","iopub.status.idle":"2023-02-22T05:28:29.713998Z","shell.execute_reply.started":"2023-02-22T05:28:20.612176Z","shell.execute_reply":"2023-02-22T05:28:29.713008Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"!unzip /kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip\n","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:28:29.715486Z","iopub.execute_input":"2023-02-22T05:28:29.716210Z","iopub.status.idle":"2023-02-22T05:28:31.600165Z","shell.execute_reply.started":"2023-02-22T05:28:29.716174Z","shell.execute_reply":"2023-02-22T05:28:31.599042Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Archive:  /kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip\n  inflating: test.csv                \n","output_type":"stream"}]},{"cell_type":"code","source":"!unzip /kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:28:31.604433Z","iopub.execute_input":"2023-02-22T05:28:31.605441Z","iopub.status.idle":"2023-02-22T05:28:33.368121Z","shell.execute_reply.started":"2023-02-22T05:28:31.605398Z","shell.execute_reply":"2023-02-22T05:28:33.366944Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Archive:  /kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\n  inflating: train.csv               \n","output_type":"stream"}]},{"cell_type":"code","source":"physical_devices = tf.config.list_physical_devices('GPU')","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:28:33.371739Z","iopub.execute_input":"2023-02-22T05:28:33.372109Z","iopub.status.idle":"2023-02-22T05:28:33.718266Z","shell.execute_reply.started":"2023-02-22T05:28:33.372074Z","shell.execute_reply":"2023-02-22T05:28:33.717120Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2023-02-22 05:28:33.489099: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-22 05:28:33.490026: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-22 05:28:33.707082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-22 05:28:33.707938: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-22 05:28:33.708786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-22 05:28:33.709538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/working/train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:28:33.719752Z","iopub.execute_input":"2023-02-22T05:28:33.721151Z","iopub.status.idle":"2023-02-22T05:28:34.567621Z","shell.execute_reply.started":"2023-02-22T05:28:33.721105Z","shell.execute_reply":"2023-02-22T05:28:34.566639Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:28:34.569287Z","iopub.execute_input":"2023-02-22T05:28:34.569945Z","iopub.status.idle":"2023-02-22T05:28:34.597802Z","shell.execute_reply.started":"2023-02-22T05:28:34.569904Z","shell.execute_reply":"2023-02-22T05:28:34.596938Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                 id                                       comment_text  toxic  \\\n0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n\n   severe_toxic  obscene  threat  insult  identity_hate  \n0             0        0       0       0              0  \n1             0        0       0       0              0  \n2             0        0       0       0              0  \n3             0        0       0       0              0  \n4             0        0       0       0              0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.count(axis=1,level=None,numeric_only=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:28:34.599182Z","iopub.execute_input":"2023-02-22T05:28:34.599513Z","iopub.status.idle":"2023-02-22T05:28:34.611556Z","shell.execute_reply.started":"2023-02-22T05:28:34.599487Z","shell.execute_reply":"2023-02-22T05:28:34.610502Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"0         6\n1         6\n2         6\n3         6\n4         6\n         ..\n159566    6\n159567    6\n159568    6\n159569    6\n159570    6\nLength: 159571, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"x=data['toxic'].value_counts()[0]\nx\n","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:28:34.612966Z","iopub.execute_input":"2023-02-22T05:28:34.613877Z","iopub.status.idle":"2023-02-22T05:28:34.632088Z","shell.execute_reply.started":"2023-02-22T05:28:34.613834Z","shell.execute_reply":"2023-02-22T05:28:34.630826Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"144277"},"metadata":{}}]},{"cell_type":"code","source":"y=data['toxic'].value_counts()[1]\ny\n","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:28:34.636709Z","iopub.execute_input":"2023-02-22T05:28:34.637047Z","iopub.status.idle":"2023-02-22T05:28:34.647014Z","shell.execute_reply.started":"2023-02-22T05:28:34.637016Z","shell.execute_reply":"2023-02-22T05:28:34.646011Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"15294"},"metadata":{}}]},{"cell_type":"code","source":"x = data['comment_text']\nx","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:28:34.649718Z","iopub.execute_input":"2023-02-22T05:28:34.650059Z","iopub.status.idle":"2023-02-22T05:28:34.662171Z","shell.execute_reply.started":"2023-02-22T05:28:34.650003Z","shell.execute_reply":"2023-02-22T05:28:34.661195Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"0         Explanation\\nWhy the edits made under my usern...\n1         D'aww! He matches this background colour I'm s...\n2         Hey man, I'm really not trying to edit war. It...\n3         \"\\nMore\\nI can't make any real suggestions on ...\n4         You, sir, are my hero. Any chance you remember...\n                                ...                        \n159566    \":::::And for the second time of asking, when ...\n159567    You should be ashamed of yourself \\n\\nThat is ...\n159568    Spitzer \\n\\nUmm, theres no actual article for ...\n159569    And it looks like it was actually you who put ...\n159570    \"\\nAnd ... I really don't think you understand...\nName: comment_text, Length: 159571, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"### ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"preprosseing\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import TextVectorization ","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:28:34.663528Z","iopub.execute_input":"2023-02-22T05:28:34.663932Z","iopub.status.idle":"2023-02-22T05:28:35.831378Z","shell.execute_reply.started":"2023-02-22T05:28:34.663899Z","shell.execute_reply":"2023-02-22T05:28:35.830305Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"X=data['comment_text']\nY=data[data.columns[2:]]\n\n","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:28:35.832798Z","iopub.execute_input":"2023-02-22T05:28:35.833381Z","iopub.status.idle":"2023-02-22T05:28:35.844129Z","shell.execute_reply.started":"2023-02-22T05:28:35.833336Z","shell.execute_reply":"2023-02-22T05:28:35.842957Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"MAX_FETURES=200000","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:28:35.845471Z","iopub.execute_input":"2023-02-22T05:28:35.846073Z","iopub.status.idle":"2023-02-22T05:28:35.877610Z","shell.execute_reply.started":"2023-02-22T05:28:35.846033Z","shell.execute_reply":"2023-02-22T05:28:35.876550Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"vecterizor = TextVectorization(max_tokens=MAX_FETURES,output_sequence_length=1800,output_mode='int')","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:28:35.878880Z","iopub.execute_input":"2023-02-22T05:28:35.879278Z","iopub.status.idle":"2023-02-22T05:28:40.655623Z","shell.execute_reply.started":"2023-02-22T05:28:35.879244Z","shell.execute_reply":"2023-02-22T05:28:40.654421Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"2023-02-22 05:28:35.916484: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-02-22 05:28:36.164679: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-22 05:28:36.165520: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-22 05:28:36.166233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-22 05:28:36.166918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-22 05:28:36.167590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-22 05:28:36.168319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-22 05:28:40.267209: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-22 05:28:40.268096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-22 05:28:40.268842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-22 05:28:40.269582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-22 05:28:40.270294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-22 05:28:40.271020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13789 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n2023-02-22 05:28:40.275750: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-02-22 05:28:40.276487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13789 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}]},{"cell_type":"code","source":"type(X)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:28:40.657083Z","iopub.execute_input":"2023-02-22T05:28:40.658071Z","iopub.status.idle":"2023-02-22T05:28:40.665988Z","shell.execute_reply.started":"2023-02-22T05:28:40.658032Z","shell.execute_reply":"2023-02-22T05:28:40.664959Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"pandas.core.series.Series"},"metadata":{}}]},{"cell_type":"code","source":"type(X.values)","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:28:40.667326Z","iopub.execute_input":"2023-02-22T05:28:40.668705Z","iopub.status.idle":"2023-02-22T05:28:40.701333Z","shell.execute_reply.started":"2023-02-22T05:28:40.668669Z","shell.execute_reply":"2023-02-22T05:28:40.700249Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"numpy.ndarray"},"metadata":{}}]},{"cell_type":"code","source":"vecterizor.adapt(X.values)","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:28:40.702988Z","iopub.execute_input":"2023-02-22T05:28:40.703425Z","iopub.status.idle":"2023-02-22T05:28:51.449739Z","shell.execute_reply.started":"2023-02-22T05:28:40.703390Z","shell.execute_reply":"2023-02-22T05:28:51.448694Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"2023-02-22 05:28:40.885913: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"vecterizor.get_vocabulary()","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:28:51.451386Z","iopub.execute_input":"2023-02-22T05:28:51.451744Z","iopub.status.idle":"2023-02-22T05:28:57.337493Z","shell.execute_reply.started":"2023-02-22T05:28:51.451715Z","shell.execute_reply":"2023-02-22T05:28:57.336287Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"['',\n '[UNK]',\n 'the',\n 'to',\n 'of',\n 'and',\n 'a',\n 'you',\n 'i',\n 'is',\n 'that',\n 'in',\n 'it',\n 'for',\n 'this',\n 'not',\n 'on',\n 'be',\n 'as',\n 'have',\n 'are',\n 'your',\n 'with',\n 'if',\n 'article',\n 'was',\n 'or',\n 'but',\n 'page',\n 'my',\n 'an',\n 'from',\n 'by',\n 'do',\n 'at',\n 'about',\n 'me',\n 'so',\n 'wikipedia',\n 'can',\n 'what',\n 'there',\n 'all',\n 'has',\n 'will',\n 'talk',\n 'please',\n 'would',\n 'its',\n 'no',\n 'one',\n 'just',\n 'like',\n 'they',\n 'he',\n 'dont',\n 'which',\n 'any',\n 'been',\n 'should',\n 'more',\n 'we',\n 'some',\n 'other',\n 'who',\n 'see',\n 'here',\n 'also',\n 'his',\n 'think',\n 'im',\n 'because',\n 'know',\n 'how',\n 'am',\n 'people',\n 'why',\n 'edit',\n 'articles',\n 'only',\n 'out',\n 'up',\n 'when',\n 'were',\n 'use',\n 'then',\n 'may',\n 'time',\n 'did',\n 'them',\n 'now',\n 'being',\n 'their',\n 'than',\n 'thanks',\n 'even',\n 'get',\n 'make',\n 'good',\n 'had',\n 'very',\n 'information',\n 'does',\n 'could',\n 'well',\n 'want',\n 'such',\n 'sources',\n 'way',\n 'name',\n 'these',\n 'deletion',\n 'pages',\n 'first',\n 'help',\n 'new',\n 'editing',\n 'source',\n 'go',\n 'need',\n 'say',\n 'section',\n 'edits',\n 'again',\n 'thank',\n 'where',\n 'user',\n 'made',\n 'many',\n 'much',\n 'really',\n 'used',\n 'most',\n 'discussion',\n 'find',\n 'same',\n 'ive',\n 'deleted',\n 'into',\n 'fuck',\n 'those',\n 'work',\n 'since',\n 'before',\n 'after',\n 'point',\n 'add',\n 'look',\n 'right',\n 'read',\n 'image',\n 'take',\n 'still',\n 'over',\n 'someone',\n 'him',\n 'two',\n 'back',\n 'too',\n 'fact',\n 'link',\n 'said',\n 'own',\n 'something',\n 'going',\n 'youre',\n 'blocked',\n 'list',\n 'stop',\n 'without',\n 'content',\n 'hi',\n 'under',\n 'editors',\n 'our',\n 'block',\n 'thats',\n 'us',\n 'added',\n 'utc',\n 'history',\n 'another',\n 'doesnt',\n 'removed',\n 'might',\n 'note',\n 'however',\n 'sure',\n 'place',\n 'never',\n 'done',\n 'welcome',\n 'her',\n 'case',\n 'put',\n 'personal',\n 'seems',\n 'reason',\n 'better',\n 'using',\n 'yourself',\n 'cant',\n 'actually',\n 'ask',\n 'comment',\n 'while',\n 'vandalism',\n 'feel',\n 'question',\n 'anything',\n 'believe',\n 'person',\n 'links',\n 'things',\n 'both',\n 'didnt',\n 'comments',\n 'best',\n 'ill',\n 'part',\n 'she',\n 'hope',\n 'policy',\n 'against',\n 'off',\n 'keep',\n 'already',\n 'free',\n 'wiki',\n 'thing',\n 'nothing',\n 'change',\n 'wrong',\n 'though',\n 'problem',\n 'remove',\n 'little',\n 'subject',\n '•',\n 'others',\n 'trying',\n 'tag',\n 'copyright',\n 'must',\n 'understand',\n 'above',\n 'few',\n 'anyone',\n 'speedy',\n 'last',\n 'issue',\n 'give',\n 'questions',\n 'agree',\n 'rather',\n 'years',\n 'let',\n '2',\n 'different',\n 'editor',\n 'long',\n 'reliable',\n 'making',\n 'world',\n 'come',\n 'sorry',\n 'isnt',\n 'reference',\n 'mean',\n 'continue',\n 'try',\n 'references',\n 'found',\n 'doing',\n 'text',\n 'great',\n 'leave',\n 'says',\n 'got',\n 'probably',\n 'english',\n 'original',\n 'every',\n '1',\n 'simply',\n 'word',\n 'users',\n 'fair',\n 'hello',\n 'either',\n 'check',\n 'least',\n 'adding',\n 'ip',\n 'show',\n 'site',\n 'state',\n 'else',\n 'delete',\n 'consensus',\n 'enough',\n 'request',\n 'far',\n 'opinion',\n 'created',\n 'around',\n 'life',\n 'day',\n 'between',\n 'through',\n 'example',\n 'view',\n 'yes',\n 'reverted',\n 'yet',\n 'etc',\n 'id',\n 'matter',\n 'shit',\n 'u',\n 'war',\n 'notable',\n 'contributions',\n 'given',\n 'thought',\n 'material',\n 'book',\n 'admin',\n 'write',\n 'post',\n 'down',\n 'account',\n 'clearly',\n 'having',\n 'encyclopedia',\n 'lot',\n 'support',\n 'real',\n 'bad',\n 'message',\n 'needs',\n 'images',\n 'tell',\n 'seem',\n 'called',\n 'maybe',\n 'evidence',\n 'instead',\n 'ever',\n '3',\n 'correct',\n 'saying',\n 'clear',\n 'always',\n 'number',\n 'important',\n 'further',\n 'quite',\n 'perhaps',\n 'old',\n '—',\n 'true',\n 'until',\n 'hate',\n 'states',\n 'whether',\n 'consider',\n 'written',\n 'claim',\n 'language',\n 'media',\n 'bit',\n 'once',\n 'guidelines',\n 'term',\n 'criteria',\n 'research',\n 'nigger',\n 'version',\n 'times',\n 'website',\n 'getting',\n 'fucking',\n 'theres',\n 'review',\n 'mention',\n 'pov',\n 'oh',\n 'makes',\n 'several',\n 'revert',\n 'considered',\n 'changes',\n 'cannot',\n 'words',\n 'idea',\n 'title',\n 'suck',\n 'address',\n 'notice',\n 'based',\n 'top',\n 'following',\n 'current',\n 'each',\n 'listed',\n 'means',\n 'possible',\n 'group',\n 'facts',\n 'regarding',\n 'care',\n 'rules',\n 'second',\n 'main',\n 'template',\n 'mentioned',\n 'general',\n 'year',\n 'attack',\n 'kind',\n 'whole',\n 'course',\n 'statement',\n 'left',\n 'hey',\n 'date',\n 'include',\n 'seen',\n 'three',\n 'issues',\n 'start',\n 'ass',\n 'ok',\n 'end',\n 'wikipedias',\n 'call',\n 'less',\n 'topic',\n 'gay',\n 'suggest',\n 'man',\n 'including',\n 'happy',\n 'sense',\n 'provide',\n 'create',\n 'big',\n 'days',\n 'myself',\n 'american',\n 'redirect',\n 'known',\n 'sentence',\n 'move',\n 'appropriate',\n 'changed',\n 'love',\n 'notability',\n 'explain',\n 'started',\n 'included',\n 'removing',\n 'project',\n 'anyway',\n 'info',\n 'mind',\n 'school',\n '2005',\n 'next',\n 'looking',\n 'although',\n 'picture',\n 'relevant',\n 'four',\n 'die',\n 'sign',\n 'answer',\n 'style',\n 'away',\n 'per',\n 'order',\n 'warning',\n 'wont',\n 'recent',\n 'youve',\n 'interest',\n 'community',\n 'summary',\n 'later',\n 'lol',\n 'claims',\n 'currently',\n 'discuss',\n 'interested',\n 'policies',\n 'attacks',\n 'especially',\n 'wish',\n 'wrote',\n 'able',\n 'specific',\n 'public',\n 'taken',\n 'writing',\n 'neutral',\n 'full',\n 'names',\n 'within',\n '4',\n 'position',\n 'related',\n 'below',\n 'line',\n 'wanted',\n 'during',\n 'appears',\n 'stuff',\n 'certainly',\n 'official',\n 'nice',\n 'itself',\n 'faith',\n 'everyone',\n 'wasnt',\n 'live',\n 'report',\n 'completely',\n 'according',\n 'unless',\n 'common',\n 'pretty',\n 'country',\n 'everything',\n 'looks',\n 'due',\n 'single',\n 'hes',\n 'process',\n 'contribs',\n 'news',\n 'involved',\n 'god',\n 'fat',\n 'therefore',\n 'obviously',\n 'remember',\n 'lead',\n 'hard',\n 'admins',\n 'came',\n 'edited',\n 'web',\n 'stay',\n 'learn',\n 'response',\n 'future',\n 'past',\n 'asked',\n 'truth',\n 'reading',\n 'power',\n '2006',\n 'stupid',\n 'entry',\n 'quote',\n 'posted',\n 'nor',\n 'talking',\n 'placed',\n '5',\n 'ago',\n 'similar',\n 'email',\n 'game',\n 'published',\n 'exactly',\n 'today',\n 'reasons',\n 'paragraph',\n 'faggot',\n 'city',\n 'argument',\n 'whatever',\n 'system',\n 'working',\n 'false',\n 'sandbox',\n 'moron',\n 'political',\n 'noticed',\n 'useful',\n 'havent',\n 'guy',\n 'high',\n 'regards',\n 'united',\n 'guess',\n 'appreciate',\n 'particular',\n 'deleting',\n 'form',\n 'books',\n 'government',\n 'dispute',\n 'five',\n 'british',\n 'reverting',\n 'major',\n 'problems',\n 'national',\n 'party',\n 'provided',\n 'often',\n 'ones',\n 'become',\n 'lets',\n 'tried',\n 'side',\n 'administrator',\n 'along',\n 'reply',\n 'almost',\n 'needed',\n 'stated',\n 'rule',\n 'took',\n 'search',\n 'knowledge',\n 'banned',\n 'cheers',\n 'taking',\n 'vandalize',\n '–',\n 'certain',\n '2007',\n 'username',\n 'fine',\n 'status',\n 'law',\n 'points',\n 'company',\n 'otherwise',\n 'uploaded',\n 'terms',\n 'explanation',\n 'generally',\n 'sort',\n 'entire',\n 'shows',\n 'description',\n 'whats',\n 'recently',\n 'follow',\n 'guys',\n '2008',\n 'likely',\n 'film',\n 'present',\n 'aware',\n 'saw',\n 'definition',\n 'cited',\n 'alone',\n 'google',\n 'music',\n 'soon',\n 'indeed',\n 'decide',\n 'ban',\n 'wp',\n 'appear',\n 'views',\n 'week',\n 'open',\n 'citation',\n 'contributing',\n 'actual',\n 'set',\n 'interesting',\n 'piece',\n 'c',\n 'short',\n 'white',\n 'told',\n 'theory',\n 'area',\n 'improve',\n 'external',\n 'small',\n 'story',\n 'contact',\n 'simple',\n '2004',\n 'various',\n 'allowed',\n 'moved',\n 'test',\n 'internet',\n 'obvious',\n 'family',\n 'band',\n 'attention',\n 'arent',\n 'proposed',\n 'jew',\n 'themselves',\n 'members',\n 'wouldnt',\n 'result',\n 'disagree',\n 'thus',\n 'cunt',\n 'went',\n 'type',\n 'sites',\n 'ie',\n 'context',\n 'mr',\n 'previous',\n 'nonsense',\n 'actions',\n 'tags',\n 'cite',\n 'works',\n '10',\n 'citations',\n 'jews',\n 'university',\n 're',\n 'enjoy',\n 'conflict',\n 'hours',\n 'shouldnt',\n 'proper',\n 'bias',\n 'category',\n 'job',\n 'longer',\n 'file',\n 'together',\n 'hell',\n 'sourced',\n 'sucks',\n 'addition',\n 'happened',\n 'avoid',\n 'automatically',\n 'author',\n 'valid',\n 'black',\n 'creating',\n 'deal',\n 'worked',\n 'npov',\n 'goes',\n 'himself',\n 'seriously',\n 'john',\n 'death',\n 'proof',\n 'respect',\n 'bitch',\n 'science',\n 'human',\n 'biased',\n 'comes',\n 'helpful',\n 'large',\n 'accepted',\n 'available',\n 'exist',\n 'series',\n 'tildes',\n 'opinions',\n 'hand',\n '6',\n 'indicate',\n 'sections',\n 'rights',\n 'necessary',\n 'act',\n 'meaning',\n 'attempt',\n 'accept',\n 'personally',\n 'statements',\n 'violation',\n 'months',\n 'criticism',\n 'accurate',\n 'action',\n 'usually',\n 'unblock',\n 'german',\n 'pig',\n 'cause',\n 'yeah',\n 'living',\n 'copy',\n 'debate',\n 'upon',\n 'assume',\n 'july',\n 'calling',\n 'standard',\n 'video',\n 'play',\n 'rest',\n 'tagged',\n 'doubt',\n 'sex',\n 'multiple',\n 'theyre',\n 'historical',\n 'serious',\n 'details',\n 'dick',\n 'youll',\n 'separate',\n 'manual',\n 'record',\n 'blocking',\n 'afd',\n 'explaining',\n 'situation',\n 'refer',\n 'wikiproject',\n 'heard',\n 'online',\n 'level',\n 'fix',\n 'asking',\n '7',\n 'complete',\n 'speak',\n 'lack',\n 'messages',\n 'none',\n 'prove',\n 'third',\n 'subjects',\n 'church',\n 'apparently',\n '2009',\n 'south',\n 'rationale',\n 'bullshit',\n 'data',\n 'directly',\n 'august',\n 'period',\n 'legal',\n 'behavior',\n 'difference',\n 'contribute',\n 'greek',\n 'huge',\n 'gets',\n 'wikipedian',\n 'couple',\n 'supposed',\n 'among',\n 'early',\n 'except',\n 'march',\n 'close',\n 'quality',\n 'space',\n 'meant',\n 'countries',\n 'run',\n 'team',\n 'uses',\n 'military',\n 'b',\n 'changing',\n 'existing',\n 'specifically',\n 'significant',\n '2010',\n 'pillars',\n 'fish',\n 'incorrect',\n 'culture',\n 'described',\n 'produce',\n 'jewish',\n '24',\n 'uk',\n 'disruptive',\n 'd',\n 'field',\n 'error',\n 'india',\n 'head',\n 'primary',\n 'friend',\n 'earlier',\n 'sometimes',\n 'outside',\n '20',\n 'purpose',\n 'administrators',\n 'modern',\n 'photo',\n 'table',\n 'particularly',\n 't',\n 'release',\n 'gave',\n 'box',\n 'cases',\n 'inclusion',\n 'born',\n 'pictures',\n 'readers',\n 'june',\n 'character',\n 'vote',\n 'okay',\n 'groups',\n 'anonymous',\n 'abuse',\n 'arguments',\n 'business',\n 'shall',\n 'sock',\n 'tutorial',\n 'january',\n 'friends',\n 'numbers',\n 'control',\n 'thinking',\n 'member',\n 'linked',\n 'happen',\n 'reported',\n 'contest',\n 'coming',\n 'takes',\n 'concerns',\n 'allow',\n 'wait',\n 'majority',\n 'giving',\n '8',\n 'bring',\n 'eg',\n 'worth',\n 'kill',\n 'totally',\n 'red',\n 'force',\n 'decided',\n 'discussed',\n 'house',\n 'finally',\n 'absolutely',\n 'putting',\n 'scientific',\n 'respond',\n 'mistake',\n 'decision',\n 'de',\n 'lost',\n 'entirely',\n '100',\n 'towards',\n 'merely',\n 'home',\n 'neither',\n 'dear',\n 'independent',\n 'international',\n 'song',\n 'balls',\n 'wants',\n 'possibly',\n 'unsigned',\n 'million',\n 'irrelevant',\n 'standards',\n 'april',\n '12',\n 'press',\n 'figure',\n 'organization',\n 'looked',\n 'inappropriate',\n 'chance',\n 'posting',\n 'population',\n 'advice',\n 'posts',\n 'north',\n 'events',\n 'unfortunately',\n 'named',\n 'album',\n ...]"},"metadata":{}}]},{"cell_type":"code","source":"vectorized_text=vecterizor(X.values)","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:28:57.339134Z","iopub.execute_input":"2023-02-22T05:28:57.339543Z","iopub.status.idle":"2023-02-22T05:29:02.033467Z","shell.execute_reply.started":"2023-02-22T05:28:57.339504Z","shell.execute_reply":"2023-02-22T05:29:02.032434Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"2023-02-22 05:29:00.412360: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2297822400 exceeds 10% of free system memory.\n","output_type":"stream"}]},{"cell_type":"code","source":"vectorized_text","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:02.035349Z","iopub.execute_input":"2023-02-22T05:29:02.035740Z","iopub.status.idle":"2023-02-22T05:29:02.044504Z","shell.execute_reply.started":"2023-02-22T05:29:02.035703Z","shell.execute_reply":"2023-02-22T05:29:02.041904Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(159571, 1800), dtype=int64, numpy=\narray([[  645,    76,     2, ...,     0,     0,     0],\n       [    1,    54,  2489, ...,     0,     0,     0],\n       [  425,   441,    70, ...,     0,     0,     0],\n       ...,\n       [32445,  7392,   383, ...,     0,     0,     0],\n       [    5,    12,   534, ...,     0,     0,     0],\n       [    5,     8,   130, ...,     0,     0,     0]])>"},"metadata":{}}]},{"cell_type":"code","source":"TextVectorization??\n","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:02.045950Z","iopub.execute_input":"2023-02-22T05:29:02.046885Z","iopub.status.idle":"2023-02-22T05:29:02.159274Z","shell.execute_reply.started":"2023-02-22T05:29:02.046840Z","shell.execute_reply":"2023-02-22T05:29:02.157821Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[0;31mInit signature:\u001b[0m \u001b[0mTextVectorization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mSource:\u001b[0m        \n\u001b[0;32mclass\u001b[0m \u001b[0mTextVectorization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_preprocessing_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPreprocessingLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m  \u001b[0;34m\"\"\"Text vectorization layer.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m  This layer has basic options for managing text in a Keras model. It\u001b[0m\n\u001b[0;34m  transforms a batch of strings (one example = one string) into either a list of\u001b[0m\n\u001b[0;34m  token indices (one example = 1D tensor of integer token indices) or a dense\u001b[0m\n\u001b[0;34m  representation (one example = 1D tensor of float values representing data\u001b[0m\n\u001b[0;34m  about the example's tokens).\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m  If desired, the user can call this layer's `adapt()` method on a dataset.\u001b[0m\n\u001b[0;34m  When this layer is adapted, it will analyze the dataset, determine the\u001b[0m\n\u001b[0;34m  frequency of individual string values, and create a 'vocabulary' from them.\u001b[0m\n\u001b[0;34m  This vocabulary can have unlimited size or be capped, depending on the\u001b[0m\n\u001b[0;34m  configuration options for this layer; if there are more unique values in the\u001b[0m\n\u001b[0;34m  input than the maximum vocabulary size, the most frequent terms will be used\u001b[0m\n\u001b[0;34m  to create the vocabulary.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m  The processing of each example contains the following steps:\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m  1. Standardize each example (usually lowercasing + punctuation stripping)\u001b[0m\n\u001b[0;34m  2. Split each example into substrings (usually words)\u001b[0m\n\u001b[0;34m  3. Recombine substrings into tokens (usually ngrams)\u001b[0m\n\u001b[0;34m  4. Index tokens (associate a unique int value with each token)\u001b[0m\n\u001b[0;34m  5. Transform each example using this index, either into a vector of ints or\u001b[0m\n\u001b[0;34m     a dense float vector.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m  Some notes on passing callables to customize splitting and normalization for\u001b[0m\n\u001b[0;34m  this layer:\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m  1. Any callable can be passed to this Layer, but if you want to serialize\u001b[0m\n\u001b[0;34m     this object you should only pass functions that are registered Keras\u001b[0m\n\u001b[0;34m     serializables (see `tf.keras.utils.register_keras_serializable` for more\u001b[0m\n\u001b[0;34m     details).\u001b[0m\n\u001b[0;34m  2. When using a custom callable for `standardize`, the data received\u001b[0m\n\u001b[0;34m     by the callable will be exactly as passed to this layer. The callable\u001b[0m\n\u001b[0;34m     should return a tensor of the same shape as the input.\u001b[0m\n\u001b[0;34m  3. When using a custom callable for `split`, the data received by the\u001b[0m\n\u001b[0;34m     callable will have the 1st dimension squeezed out - instead of\u001b[0m\n\u001b[0;34m     `[[\"string to split\"], [\"another string to split\"]]`, the Callable will\u001b[0m\n\u001b[0;34m     see `[\"string to split\", \"another string to split\"]`. The callable should\u001b[0m\n\u001b[0;34m     return a Tensor with the first dimension containing the split tokens -\u001b[0m\n\u001b[0;34m     in this example, we should see something like `[[\"string\", \"to\",\u001b[0m\n\u001b[0;34m     \"split\"], [\"another\", \"string\", \"to\", \"split\"]]`. This makes the callable\u001b[0m\n\u001b[0;34m     site natively compatible with `tf.strings.split()`.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m  Args:\u001b[0m\n\u001b[0;34m    max_tokens: The maximum size of the vocabulary for this layer. If None,\u001b[0m\n\u001b[0;34m      there is no cap on the size of the vocabulary. Note that this vocabulary\u001b[0m\n\u001b[0;34m      contains 1 OOV token, so the effective number of tokens is `(max_tokens -\u001b[0m\n\u001b[0;34m      1 - (1 if output_mode == \"int\" else 0))`.\u001b[0m\n\u001b[0;34m    standardize: Optional specification for standardization to apply to the\u001b[0m\n\u001b[0;34m      input text. Values can be None (no standardization),\u001b[0m\n\u001b[0;34m      `\"lower_and_strip_punctuation\"` (lowercase and remove punctuation) or a\u001b[0m\n\u001b[0;34m      Callable. Default is `\"lower_and_strip_punctuation\"`.\u001b[0m\n\u001b[0;34m    split: Optional specification for splitting the input text. Values can be\u001b[0m\n\u001b[0;34m      None (no splitting), `\"whitespace\"` (split on ASCII whitespace), or a\u001b[0m\n\u001b[0;34m      Callable. The default is `\"whitespace\"`.\u001b[0m\n\u001b[0;34m    ngrams: Optional specification for ngrams to create from the possibly-split\u001b[0m\n\u001b[0;34m      input text. Values can be None, an integer or tuple of integers; passing\u001b[0m\n\u001b[0;34m      an integer will create ngrams up to that integer, and passing a tuple of\u001b[0m\n\u001b[0;34m      integers will create ngrams for the specified values in the tuple. Passing\u001b[0m\n\u001b[0;34m      None means that no ngrams will be created.\u001b[0m\n\u001b[0;34m    output_mode: Optional specification for the output of the layer. Values can\u001b[0m\n\u001b[0;34m      be `\"int\"`, `\"multi_hot\"`, `\"count\"` or `\"tf_idf\"`, configuring the layer\u001b[0m\n\u001b[0;34m      as follows:\u001b[0m\n\u001b[0;34m        - `\"int\"`: Outputs integer indices, one integer index per split string\u001b[0m\n\u001b[0;34m          token. When `output_mode == \"int\"`, 0 is reserved for masked\u001b[0m\n\u001b[0;34m          locations; this reduces the vocab size to\u001b[0m\n\u001b[0;34m          `max_tokens - 2` instead of `max_tokens - 1`.\u001b[0m\n\u001b[0;34m        - `\"multi_hot\"`: Outputs a single int array per batch, of either\u001b[0m\n\u001b[0;34m          vocab_size or max_tokens size, containing 1s in all elements where the\u001b[0m\n\u001b[0;34m          token mapped to that index exists at least once in the batch item.\u001b[0m\n\u001b[0;34m        - `\"count\"`: Like `\"multi_hot\"`, but the int array contains a count of\u001b[0m\n\u001b[0;34m          the number of times the token at that index appeared in the\u001b[0m\n\u001b[0;34m          batch item.\u001b[0m\n\u001b[0;34m        - `\"tf_idf\"`: Like `\"multi_hot\"`, but the TF-IDF algorithm is applied to\u001b[0m\n\u001b[0;34m          find the value in each token slot.\u001b[0m\n\u001b[0;34m      For `\"int\"` output, any shape of input and output is supported. For all\u001b[0m\n\u001b[0;34m      other output modes, currently only rank 1 inputs (and rank 2 outputs after\u001b[0m\n\u001b[0;34m      splitting) are supported.\u001b[0m\n\u001b[0;34m    output_sequence_length: Only valid in INT mode. If set, the output will have\u001b[0m\n\u001b[0;34m      its time dimension padded or truncated to exactly `output_sequence_length`\u001b[0m\n\u001b[0;34m      values, resulting in a tensor of shape\u001b[0m\n\u001b[0;34m      `(batch_size, output_sequence_length)` regardless of how many tokens\u001b[0m\n\u001b[0;34m      resulted from the splitting step. Defaults to None.\u001b[0m\n\u001b[0;34m    pad_to_max_tokens: Only valid in  `\"multi_hot\"`, `\"count\"`, and `\"tf_idf\"`\u001b[0m\n\u001b[0;34m      modes. If True, the output will have its feature axis padded to\u001b[0m\n\u001b[0;34m      `max_tokens` even if the number of unique tokens in the vocabulary is less\u001b[0m\n\u001b[0;34m      than max_tokens, resulting in a tensor of shape `(batch_size, max_tokens)`\u001b[0m\n\u001b[0;34m      regardless of vocabulary size. Defaults to False.\u001b[0m\n\u001b[0;34m    vocabulary: Optional. Either an array of strings or a string path to a text\u001b[0m\n\u001b[0;34m      file. If passing an array, can pass a tuple, list, 1D numpy array, or 1D\u001b[0m\n\u001b[0;34m      tensor containing the string vocbulary terms. If passing a file path, the\u001b[0m\n\u001b[0;34m      file should contain one line per term in the vocabulary. If this argument\u001b[0m\n\u001b[0;34m      is set, there is no need to `adapt` the layer.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m  Example:\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m  This example instantiates a `TextVectorization` layer that lowercases text,\u001b[0m\n\u001b[0;34m  splits on whitespace, strips punctuation, and outputs integer vocab indices.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m  >>> text_dataset = tf.data.Dataset.from_tensor_slices([\"foo\", \"bar\", \"baz\"])\u001b[0m\n\u001b[0;34m  >>> max_features = 5000  # Maximum vocab size.\u001b[0m\n\u001b[0;34m  >>> max_len = 4  # Sequence length to pad the outputs to.\u001b[0m\n\u001b[0;34m  >>>\u001b[0m\n\u001b[0;34m  >>> # Create the layer.\u001b[0m\n\u001b[0;34m  >>> vectorize_layer = tf.keras.layers.TextVectorization(\u001b[0m\n\u001b[0;34m  ...  max_tokens=max_features,\u001b[0m\n\u001b[0;34m  ...  output_mode='int',\u001b[0m\n\u001b[0;34m  ...  output_sequence_length=max_len)\u001b[0m\n\u001b[0;34m  >>>\u001b[0m\n\u001b[0;34m  >>> # Now that the vocab layer has been created, call `adapt` on the text-only\u001b[0m\n\u001b[0;34m  >>> # dataset to create the vocabulary. You don't have to batch, but for large\u001b[0m\n\u001b[0;34m  >>> # datasets this means we're not keeping spare copies of the dataset.\u001b[0m\n\u001b[0;34m  >>> vectorize_layer.adapt(text_dataset.batch(64))\u001b[0m\n\u001b[0;34m  >>>\u001b[0m\n\u001b[0;34m  >>> # Create the model that uses the vectorize text layer\u001b[0m\n\u001b[0;34m  >>> model = tf.keras.models.Sequential()\u001b[0m\n\u001b[0;34m  >>>\u001b[0m\n\u001b[0;34m  >>> # Start by creating an explicit input layer. It needs to have a shape of\u001b[0m\n\u001b[0;34m  >>> # (1,) (because we need to guarantee that there is exactly one string\u001b[0m\n\u001b[0;34m  >>> # input per batch), and the dtype needs to be 'string'.\u001b[0m\n\u001b[0;34m  >>> model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\u001b[0m\n\u001b[0;34m  >>>\u001b[0m\n\u001b[0;34m  >>> # The first layer in our model is the vectorization layer. After this\u001b[0m\n\u001b[0;34m  >>> # layer, we have a tensor of shape (batch_size, max_len) containing vocab\u001b[0m\n\u001b[0;34m  >>> # indices.\u001b[0m\n\u001b[0;34m  >>> model.add(vectorize_layer)\u001b[0m\n\u001b[0;34m  >>>\u001b[0m\n\u001b[0;34m  >>> # Now, the model can map strings to integers, and you can add an embedding\u001b[0m\n\u001b[0;34m  >>> # layer to map these integers to learned embeddings.\u001b[0m\n\u001b[0;34m  >>> input_data = [[\"foo qux bar\"], [\"qux baz\"]]\u001b[0m\n\u001b[0;34m  >>> model.predict(input_data)\u001b[0m\n\u001b[0;34m  array([[2, 1, 4, 0],\u001b[0m\n\u001b[0;34m         [1, 3, 0, 0]])\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m  Example:\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m  This example instantiates a `TextVectorization` layer by passing a list\u001b[0m\n\u001b[0;34m  of vocabulary terms to the layer's `__init__()` method.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m  >>> vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\u001b[0m\n\u001b[0;34m  >>> max_len = 4  # Sequence length to pad the outputs to.\u001b[0m\n\u001b[0;34m  >>>\u001b[0m\n\u001b[0;34m  >>> # Create the layer, passing the vocab directly. You can also pass the\u001b[0m\n\u001b[0;34m  >>> # vocabulary arg a path to a file containing one vocabulary word per\u001b[0m\n\u001b[0;34m  >>> # line.\u001b[0m\n\u001b[0;34m  >>> vectorize_layer = tf.keras.layers.TextVectorization(\u001b[0m\n\u001b[0;34m  ...  max_tokens=max_features,\u001b[0m\n\u001b[0;34m  ...  output_mode='int',\u001b[0m\n\u001b[0;34m  ...  output_sequence_length=max_len,\u001b[0m\n\u001b[0;34m  ...  vocabulary=vocab_data)\u001b[0m\n\u001b[0;34m  >>>\u001b[0m\n\u001b[0;34m  >>> # Because we've passed the vocabulary directly, we don't need to adapt\u001b[0m\n\u001b[0;34m  >>> # the layer - the vocabulary is already set. The vocabulary contains the\u001b[0m\n\u001b[0;34m  >>> # padding token ('') and OOV token ('[UNK]') as well as the passed tokens.\u001b[0m\n\u001b[0;34m  >>> vectorize_layer.get_vocabulary()\u001b[0m\n\u001b[0;34m  ['', '[UNK]', 'earth', 'wind', 'and', 'fire']\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m  \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m  \u001b[0;31m# TODO(momernick): Add an examples section to the docstring.\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m               \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m               \u001b[0mstandardize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"lower_and_strip_punctuation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m               \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"whitespace\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m               \u001b[0mngrams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m               \u001b[0moutput_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"int\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m               \u001b[0moutput_sequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m               \u001b[0mpad_to_max_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m               \u001b[0mvocabulary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m               \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;31m# This layer only applies to string processing, and so should only have\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;31m# a dtype of 'string'.\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TextVectorization may only have a dtype of string.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32melif\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;31m# 'standardize' must be one of (None, LOWER_AND_STRIP_PUNCTUATION, callable)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mlayer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_string_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mstandardize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mallowable_strings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOWER_AND_STRIP_PUNCTUATION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mlayer_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"TextVectorization\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0marg_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"standardize\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mallow_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mallow_callables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;31m# 'split' must be one of (None, SPLIT_ON_WHITESPACE, callable)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mlayer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_string_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mallowable_strings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSPLIT_ON_WHITESPACE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mlayer_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"TextVectorization\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0marg_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"split\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mallow_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mallow_callables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;31m# Support deprecated names for output_modes.\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0moutput_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0moutput_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMULTI_HOT\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0moutput_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tf-idf\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0moutput_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTF_IDF\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;31m# 'output_mode' must be one of (None, INT, COUNT, MULTI_HOT, TF_IDF)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mlayer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_string_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0moutput_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mallowable_strings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCOUNT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMULTI_HOT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTF_IDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mlayer_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"TextVectorization\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0marg_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"output_mode\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mallow_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;31m# 'ngrams' must be one of (None, int, tuple(int))\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mngrams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mngrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`ngrams` must be None, an integer, or a tuple of \"\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m                        \u001b[0;34m\"integers. Got %s\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;31m# 'output_sequence_length' must be one of (None, int) and is only\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;31m# set if output_mode is INT.\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mINT\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_sequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m                                    \u001b[0;34m(\u001b[0m\u001b[0moutput_sequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`output_sequence_length` must be either None or an \"\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m                       \u001b[0;34m\"integer when `output_mode` is 'int'. \"\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m                       \u001b[0;34m\"Got %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0moutput_sequence_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0moutput_mode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mINT\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0moutput_sequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`output_sequence_length` must not be set if \"\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m                       \u001b[0;34m\"`output_mode` is not 'int'.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ngrams_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrams\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ngrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngrams\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ngrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrams\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_mode\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_sequence_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_sequence_length\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;31m# Drop deprecated config options.\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"vocabulary_size\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mbase_preprocessing_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_kpl_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TextVectorization\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_lookup_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring_lookup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStringLookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mvocabulary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mpad_to_max_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_to_max_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mmask_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0moutput_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_mode\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_mode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mINT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mINT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_sequence_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_lookup_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0moutput_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mINT\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m                    \u001b[0;32melse\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_lookup_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mfinalize_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_lookup_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mreset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=method-hidden\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_lookup_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mget_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Returns the current vocabulary of the layer.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    Args:\u001b[0m\n\u001b[0;34m      include_special_tokens: If True, the returned vocabulary will include\u001b[0m\n\u001b[0;34m        the padding and OOV tokens, and a term's index in the vocabulary will\u001b[0m\n\u001b[0;34m        equal the term's index when calling the layer. If False, the returned\u001b[0m\n\u001b[0;34m        vocabulary will not include any padding or OOV tokens.\u001b[0m\n\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_lookup_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_special_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mvocabulary_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Gets the current size of the layer's vocabulary.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    Returns:\u001b[0m\n\u001b[0;34m      The integer size of the voculary, including optional mask and oov indices.\u001b[0m\n\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_lookup_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;31m# This does not include the 'vocabulary' arg, since if the vocab was passed\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;31m# at init time it's now stored in variable state - we don't need to\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;31m# pull it off disk again.\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;34m\"max_tokens\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_lookup_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;34m\"standardize\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;34m\"ngrams\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ngrams_arg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;34m\"output_mode\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;34m\"output_sequence_length\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_sequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;34m\"pad_to_max_tokens\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_lookup_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_to_max_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mbase_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTextVectorization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mset_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midf_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Sets vocabulary (and optionally document frequency) data for this layer.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    This method sets the vocabulary and idf weights for this layer directly,\u001b[0m\n\u001b[0;34m    instead of analyzing a dataset through 'adapt'. It should be used whenever\u001b[0m\n\u001b[0;34m    the vocab (and optionally document frequency) information is already known.\u001b[0m\n\u001b[0;34m    If vocabulary data is already present in the layer, this method will replace\u001b[0m\n\u001b[0;34m    it.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    Args:\u001b[0m\n\u001b[0;34m      vocabulary: Either an array or a string path to a text file. If passing an\u001b[0m\n\u001b[0;34m        array, can pass a tuple, list, 1D numpy array, or 1D tensor containing\u001b[0m\n\u001b[0;34m        the vocbulary terms. If passing a file path, the file should contain one\u001b[0m\n\u001b[0;34m        line per term in the vocabulary.\u001b[0m\n\u001b[0;34m      idf_weights: A tuple, list, 1D numpy array, or 1D tensor of inverse\u001b[0m\n\u001b[0;34m        document frequency weights with equal length to vocabulary. Must be set\u001b[0m\n\u001b[0;34m        if `output_mode` is `\"tf_idf\"`. Should not be set otherwise.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    Raises:\u001b[0m\n\u001b[0;34m      ValueError: If there are too many inputs, the inputs do not match, or\u001b[0m\n\u001b[0;34m        input data is missing.\u001b[0m\n\u001b[0;34m      RuntimeError: If the vocabulary cannot be set when this function is\u001b[0m\n\u001b[0;34m        called. This happens when `\"multi_hot\"`, `\"count\"`, and \"tf_idf\" modes,\u001b[0m\n\u001b[0;34m        if `pad_to_max_tokens` is False and the layer itself has already been\u001b[0m\n\u001b[0;34m        called.\u001b[0m\n\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_lookup_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midf_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midf_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;31m# We have to use 'and not ==' here, because input_shape[1] !/== 1 can result\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;31m# in None for undefined shape axes. If using 'and !=', this causes the\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;31m# expression to evaluate to False instead of True if the shape is undefined;\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;31m# the expression needs to evaluate to True in that case.\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=g-comparison-negation\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0;34m\"When using TextVectorization to tokenize strings, the innermost \"\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0;34m\"dimension of the input array must be 1, got shape \"\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0;34m\"{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTextVectorization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0m_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLOWER_AND_STRIP_PUNCTUATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ragged\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mlowercase_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mragged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_flat_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;31m# Depending on configuration, we may never touch the non-data tensor\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;31m# in the ragged inputs tensor. If that is the case, and this is the\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;31m# only layer in the keras model, running it will throw an error.\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;31m# To get around this, we wrap the result in an identity.\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mlowercase_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlowercase_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mlowercase_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregex_replace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlowercase_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEFAULT_STRIP_REGEX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m                                        \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not a supported standardization. \"\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m                        \u001b[0;34m\"TextVectorization supports the following options \"\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m                        \u001b[0;34m\"for `standardize`: None, \"\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m                        \u001b[0;34m\"'lower_and_strip_punctuation', or a \"\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m                        \u001b[0;34m\"Callable.\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0;31m# If we are splitting, we validate that the 1st axis is of dimension 1 and\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0;31m# so can be squeezed out. We do this here instead of after splitting for\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0;31m# performance reasons - it's more expensive to squeeze a ragged tensor.\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSPLIT_ON_WHITESPACE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;31m# This treats multiple whitespaces as one whitespace, and strips leading\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;31m# and trailing whitespace.\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not a supported splitting.\"\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m             \u001b[0;34m\"TextVectorization supports the following options \"\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m             \u001b[0;34m\"for `split`: None, 'whitespace', or a Callable.\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;31m# Note that 'inputs' here can be either ragged or dense depending on the\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;31m# configuration choices for this Layer. The strings.ngrams op, however, does\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;31m# support both ragged and dense inputs.\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ngrams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m          \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ngrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m  \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;31m# If we're not doing any output processing, return right away.\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_mode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mlookup_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_lookup_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;31m# For any non-int output, we can return directly from the underlying layer.\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_mode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mINT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0mlookup_data\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;31m# If we have a ragged tensor, we can pad during the conversion to dense.\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ragged\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlookup_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0;31m# If output sequence length is None, to_tensor will pad the last dimension\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0;31m# to the bounding shape of the ragged dimension.\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_sequence_length\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0mlookup_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;31m# If we have a dense tensor, we need to pad/trim directly.\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_sequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0;31m# Maybe trim the output.\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0mlookup_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_sequence_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0;31m# Maybe pad the output. We need to be careful to use dynamic shape here as\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0;31m# required_space_to_batch_paddings requires a fully known shape.\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlookup_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0mpadded_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_sequence_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequired_space_to_batch_paddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m      \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlookup_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mlookup_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mFile:\u001b[0m           /opt/conda/lib/python3.7/site-packages/keras/layers/preprocessing/text_vectorization.py\n\u001b[0;31mType:\u001b[0m           ABCMeta\n\u001b[0;31mSubclasses:\u001b[0m     \n"},"metadata":{}}]},{"cell_type":"markdown","source":"yveygywtev","metadata":{}},{"cell_type":"code","source":"dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, Y))\ndataset = dataset.cache()\ndataset = dataset.shuffle(160000)\ndataset = dataset.batch(16)\ndataset = dataset.prefetch(8)","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:02.160817Z","iopub.execute_input":"2023-02-22T05:29:02.161181Z","iopub.status.idle":"2023-02-22T05:29:02.192086Z","shell.execute_reply.started":"2023-02-22T05:29:02.161147Z","shell.execute_reply":"2023-02-22T05:29:02.190969Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"dataset.as_numpy_iterator().next()\n(batch_x,batch_y)=dataset.as_numpy_iterator().next()","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:02.193361Z","iopub.execute_input":"2023-02-22T05:29:02.194064Z","iopub.status.idle":"2023-02-22T05:29:06.530294Z","shell.execute_reply.started":"2023-02-22T05:29:02.194024Z","shell.execute_reply":"2023-02-22T05:29:06.529256Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"2023-02-22 05:29:02.197736: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2297822400 exceeds 10% of free system memory.\n2023-02-22 05:29:04.448443: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2297822400 exceeds 10% of free system memory.\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_x.shape","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:06.535219Z","iopub.execute_input":"2023-02-22T05:29:06.537433Z","iopub.status.idle":"2023-02-22T05:29:06.547181Z","shell.execute_reply.started":"2023-02-22T05:29:06.537397Z","shell.execute_reply":"2023-02-22T05:29:06.546152Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"(16, 1800)"},"metadata":{}}]},{"cell_type":"code","source":"batch_y.shape","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:06.551861Z","iopub.execute_input":"2023-02-22T05:29:06.554657Z","iopub.status.idle":"2023-02-22T05:29:06.564086Z","shell.execute_reply.started":"2023-02-22T05:29:06.554622Z","shell.execute_reply":"2023-02-22T05:29:06.563049Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"(16, 6)"},"metadata":{}}]},{"cell_type":"markdown","source":"competing the pieline by particining the data set into train test and vald\n","metadata":{}},{"cell_type":"code","source":"train=dataset.take(int(len(dataset)*7))\nvald=dataset.skip(int(len(dataset)*7)).take(int(len(dataset)*2))\ntest=dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))\n","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:06.567069Z","iopub.execute_input":"2023-02-22T05:29:06.568254Z","iopub.status.idle":"2023-02-22T05:29:06.583572Z","shell.execute_reply.started":"2023-02-22T05:29:06.568202Z","shell.execute_reply":"2023-02-22T05:29:06.582656Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,LSTM,Dropout,Bidirectional,Embedding","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:06.593610Z","iopub.execute_input":"2023-02-22T05:29:06.595889Z","iopub.status.idle":"2023-02-22T05:29:06.602024Z","shell.execute_reply.started":"2023-02-22T05:29:06.595855Z","shell.execute_reply":"2023-02-22T05:29:06.601221Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n# Create the embedding layer \nmodel.add(Embedding(MAX_FETURES+1, 32))\n# Bidirectional LSTM Layer\nmodel.add(Bidirectional(LSTM(32, activation='tanh')))\n# Feature extractor Fully connected layers\nmodel.add(Dense(128, activation='relu'))\n#model.add(Dropout(0.2))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.01))\nmodel.add(Dense(128, activation='relu'))\n# Final layer \nmodel.add(Dense(6, activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:06.606798Z","iopub.execute_input":"2023-02-22T05:29:06.609453Z","iopub.status.idle":"2023-02-22T05:29:07.190801Z","shell.execute_reply.started":"2023-02-22T05:29:06.609419Z","shell.execute_reply":"2023-02-22T05:29:07.189595Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='BinaryCrossentropy',optimizer='Adam')","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:07.192306Z","iopub.execute_input":"2023-02-22T05:29:07.192674Z","iopub.status.idle":"2023-02-22T05:29:07.208174Z","shell.execute_reply.started":"2023-02-22T05:29:07.192635Z","shell.execute_reply":"2023-02-22T05:29:07.206932Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:07.210051Z","iopub.execute_input":"2023-02-22T05:29:07.210334Z","iopub.status.idle":"2023-02-22T05:29:07.219379Z","shell.execute_reply.started":"2023-02-22T05:29:07.210309Z","shell.execute_reply":"2023-02-22T05:29:07.218138Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, None, 32)          6400032   \n_________________________________________________________________\nbidirectional (Bidirectional (None, 64)                16640     \n_________________________________________________________________\ndense (Dense)                (None, 128)               8320      \n_________________________________________________________________\ndense_1 (Dense)              (None, 256)               33024     \n_________________________________________________________________\ndropout (Dropout)            (None, 256)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 128)               32896     \n_________________________________________________________________\ndense_3 (Dense)              (None, 6)                 774       \n=================================================================\nTotal params: 6,491,686\nTrainable params: 6,491,686\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:55.206165Z","iopub.execute_input":"2023-02-22T05:29:55.206835Z","iopub.status.idle":"2023-02-22T05:29:55.211477Z","shell.execute_reply.started":"2023-02-22T05:29:55.206798Z","shell.execute_reply":"2023-02-22T05:29:55.210270Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"es = EarlyStopping(monitor='val_loss',patience = 3, verbose=1,restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:58.046685Z","iopub.execute_input":"2023-02-22T05:29:58.047210Z","iopub.status.idle":"2023-02-22T05:29:58.052723Z","shell.execute_reply.started":"2023-02-22T05:29:58.047170Z","shell.execute_reply":"2023-02-22T05:29:58.051529Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train, epochs=75,validation_data=vald,callbacks=[es])","metadata":{"execution":{"iopub.status.busy":"2023-02-22T06:17:14.130410Z","iopub.execute_input":"2023-02-22T06:17:14.130707Z","iopub.status.idle":"2023-02-22T06:17:16.411831Z","shell.execute_reply.started":"2023-02-22T06:17:14.130680Z","shell.execute_reply":"2023-02-22T06:17:16.410268Z"},"trusted":true},"execution_count":41,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/1671769203.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvald\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1170\u001b[0m           self._maybe_load_initial_epoch_from_ckpt(initial_epoch))\n\u001b[1;32m   1171\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1173\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    694\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    717\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 719\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m       \u001b[0;31m# Delete the resource when this object is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3119\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3120\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 3121\u001b[0;31m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0m\u001b[1;32m   3122\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3123\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n","metadata":{"execution":{"iopub.status.busy":"2023-02-22T06:17:16.413233Z","iopub.status.idle":"2023-02-22T06:17:16.413671Z","shell.execute_reply.started":"2023-02-22T06:17:16.413460Z","shell.execute_reply":"2023-02-22T06:17:16.413479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,2))\npd.DataFrame(history.history).plot()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:07.491337Z","iopub.status.idle":"2023-02-22T05:29:07.493570Z","shell.execute_reply.started":"2023-02-22T05:29:07.493281Z","shell.execute_reply":"2023-02-22T05:29:07.493308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"predition time","metadata":{}},{"cell_type":"code","source":"batch=test.as_numpy_iterator().next() ","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:07.495284Z","iopub.status.idle":"2023-02-22T05:29:07.496235Z","shell.execute_reply.started":"2023-02-22T05:29:07.495955Z","shell.execute_reply":"2023-02-22T05:29:07.495994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_text=vecterizor('Fuck you BITCH. your are a Nigga')","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:07.497662Z","iopub.status.idle":"2023-02-22T05:29:07.499910Z","shell.execute_reply.started":"2023-02-22T05:29:07.499598Z","shell.execute_reply":"2023-02-22T05:29:07.499626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_text","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:07.501670Z","iopub.status.idle":"2023-02-22T05:29:07.502255Z","shell.execute_reply.started":"2023-02-22T05:29:07.501936Z","shell.execute_reply":"2023-02-22T05:29:07.501962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.expand_dims(input_text,0)","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:07.504217Z","iopub.status.idle":"2023-02-22T05:29:07.504762Z","shell.execute_reply.started":"2023-02-22T05:29:07.504469Z","shell.execute_reply":"2023-02-22T05:29:07.504494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.colums[2:]","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:07.507427Z","iopub.status.idle":"2023-02-22T05:29:07.507912Z","shell.execute_reply.started":"2023-02-22T05:29:07.507655Z","shell.execute_reply":"2023-02-22T05:29:07.507678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.predict(np.expand_dims(input_text,0))","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:07.510612Z","iopub.status.idle":"2023-02-22T05:29:07.511719Z","shell.execute_reply.started":"2023-02-22T05:29:07.511449Z","shell.execute_reply":"2023-02-22T05:29:07.511473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.predict(np.expand_dims(input_text,0))","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:07.512898Z","iopub.status.idle":"2023-02-22T05:29:07.513767Z","shell.execute_reply.started":"2023-02-22T05:29:07.513487Z","shell.execute_reply":"2023-02-22T05:29:07.513511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_X,batch_Y=test.as_numpy_iterator().next() ","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:07.515264Z","iopub.status.idle":"2023-02-22T05:29:07.516157Z","shell.execute_reply.started":"2023-02-22T05:29:07.515878Z","shell.execute_reply":"2023-02-22T05:29:07.515901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(model.predict(batch_X)>0.5).astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:07.517776Z","iopub.status.idle":"2023-02-22T05:29:07.519712Z","shell.execute_reply.started":"2023-02-22T05:29:07.519433Z","shell.execute_reply":"2023-02-22T05:29:07.519459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_Y","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:07.521639Z","iopub.status.idle":"2023-02-22T05:29:07.522190Z","shell.execute_reply.started":"2023-02-22T05:29:07.521899Z","shell.execute_reply":"2023-02-22T05:29:07.521924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res=model.predict(np.expand_dims(input_text,0))","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:07.524246Z","iopub.status.idle":"2023-02-22T05:29:07.524776Z","shell.execute_reply.started":"2023-02-22T05:29:07.524499Z","shell.execute_reply":"2023-02-22T05:29:07.524524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"res","metadata":{}},{"cell_type":"code","source":"res","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:07.526876Z","iopub.status.idle":"2023-02-22T05:29:07.527387Z","shell.execute_reply.started":"2023-02-22T05:29:07.527123Z","shell.execute_reply":"2023-02-22T05:29:07.527146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:07.529410Z","iopub.status.idle":"2023-02-22T05:29:07.529957Z","shell.execute_reply.started":"2023-02-22T05:29:07.529672Z","shell.execute_reply":"2023-02-22T05:29:07.529697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pre = Precision()\nre = Recall()\nacc = CategoricalAccuracy()","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:07.532000Z","iopub.status.idle":"2023-02-22T05:29:07.532539Z","shell.execute_reply.started":"2023-02-22T05:29:07.532261Z","shell.execute_reply":"2023-02-22T05:29:07.532283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for batch in test.as_numpy_iterator(): \n    # Unpack the batch \n    X_true, y_true = batch\n    # Make a prediction \n    yhat = model.predict(X_true)\n    \n    # Flatten the predictions\n    y_true = y_true.flatten()\n    yhat = yhat.flatten()\n    \n    pre.update_state(y_true, yhat)\n    re.update_state(y_true, yhat)\n    acc.update_state(y_true, yhat)","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:07.534590Z","iopub.status.idle":"2023-02-22T05:29:07.535120Z","shell.execute_reply.started":"2023-02-22T05:29:07.534838Z","shell.execute_reply":"2023-02-22T05:29:07.534862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Precision: {pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy:{acc.result().numpy()}')","metadata":{"execution":{"iopub.status.busy":"2023-02-22T05:29:07.537184Z","iopub.status.idle":"2023-02-22T05:29:07.537664Z","shell.execute_reply.started":"2023-02-22T05:29:07.537424Z","shell.execute_reply":"2023-02-22T05:29:07.537446Z"},"trusted":true},"execution_count":null,"outputs":[]}]}